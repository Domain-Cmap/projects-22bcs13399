import React, { useEffect, useRef, useState } from 'react';
import * as tf from '@tensorflow/tfjs';
import * as faceLandmarksDetection from '@tensorflow-models/face-landmarks-detection';

function App() {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const [model, setModel] = useState<faceLandmarksDetection.FaceLandmarksDetector | null>(null);
  const [stressLevel, setStressLevel] = useState<number | null>(null);
  const [isLoading, setIsLoading] = useState(true);
  const [error, setError] = useState<string | null>(null);

  // Initialize face detection model
  useEffect(() => {
    const initModel = async () => {
      try {
        const model = await faceLandmarksDetection.load(
          faceLandmarksDetection.SupportedPackages.mediapipeFacemesh,
          { maxFaces: 1 }
        );
        setModel(model);
        setIsLoading(false);
      } catch (err) {
        setError('Failed to load face detection model');
        setIsLoading(false);
      }
    };

    initModel();
  }, []);

  // Initialize webcam
  useEffect(() => {
    const setupCamera = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { width: 640, height: 480 },
          audio: false,
        });

        if (videoRef.current) {
          videoRef.current.srcObject = stream;
        }
      } catch (err) {
        setError('Failed to access webcam');
      }
    };

    setupCamera();

    return () => {
      if (videoRef.current?.srcObject) {
        const tracks = (videoRef.current.srcObject as MediaStream).getTracks();
        tracks.forEach(track => track.stop());
      }
    };
  }, []);

  // Analyze facial features and predict stress
  const analyzeFace = async () => {
    if (!model || !videoRef.current || !canvasRef.current) return;

    const predictions = await model.estimateFaces({
      input: videoRef.current,
      returnTensors: false,
      flipHorizontal: false,
      predictIrises: true
    });

    if (predictions.length > 0) {
      const face = predictions[0];
      
      // Extract relevant facial features
      const eyeOpenness = calculateEyeOpenness(face);
      const mouthTension = calculateMouthTension(face);
      const browFurrow = calculateBrowFurrow(face);

      // Simple stress calculation based on facial features
      const stress = predictStressLevel(eyeOpenness, mouthTension, browFurrow);
      setStressLevel(stress);

      // Draw face landmarks
      drawFaceLandmarks(face, canvasRef.current);
    }
  };

  // Calculate eye openness from landmarks
  const calculateEyeOpenness = (face: any) => {
    const leftEye = face.annotations.leftEyeUpper0;
    const rightEye = face.annotations.rightEyeUpper0;
    
    // Calculate average eye height
    const leftHeight = Math.abs(leftEye[3][1] - leftEye[7][1]);
    const rightHeight = Math.abs(rightEye[3][1] - rightEye[7][1]);
    
    return (leftHeight + rightHeight) / 2;
  };

  // Calculate mouth tension from landmarks
  const calculateMouthTension = (face: any) => {
    const upperLip = face.annotations.lipsUpperOuter;
    const lowerLip = face.annotations.lipsLowerOuter;
    
    // Calculate mouth height
    return Math.abs(upperLip[5][1] - lowerLip[5][1]);
  };

  // Calculate brow furrow from landmarks
  const calculateBrowFurrow = (face: any) => {
    const leftBrow = face.annotations.leftEyebrowUpper;
    const rightBrow = face.annotations.rightEyebrowUpper;
    
    // Calculate brow position
    const leftHeight = leftBrow[2][1];
    const rightHeight = rightBrow[2][1];
    
    return Math.abs(leftHeight - rightHeight);
  };

  // Predict stress level based on facial features
  const predictStressLevel = (eyeOpenness: number, mouthTension: number, browFurrow: number) => {
    // Normalize values
    const normalizedEye = Math.min(eyeOpenness / 30, 1);
    const normalizedMouth = Math.min(mouthTension / 20, 1);
    const normalizedBrow = Math.min(browFurrow / 10, 1);

    // Calculate stress score (0-1)
    return (normalizedEye * 0.3 + normalizedMouth * 0.3 + normalizedBrow * 0.4);
  };

  // Draw face landmarks on canvas
  const drawFaceLandmarks = (face: any, canvas: HTMLCanvasElement) => {
    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.fillStyle = '#32CD32';
    ctx.strokeStyle = '#32CD32';
    ctx.lineWidth = 1;

    // Draw all landmarks
    face.scaledMesh.forEach((point: number[]) => {
      ctx.beginPath();
      ctx.arc(point[0], point[1], 1, 0, 2 * Math.PI);
      ctx.fill();
    });
  };

  // Run face analysis loop
  useEffect(() => {
    let animationFrame: number;

    const runFaceDetection = async () => {
      await analyzeFace();
      animationFrame = requestAnimationFrame(runFaceDetection);
    };

    if (!isLoading && !error) {
      runFaceDetection();
    }

    return () => {
      if (animationFrame) {
        cancelAnimationFrame(animationFrame);
      }
    };
  }, [isLoading, error, model]);

  const getStressLabel = (value: number): string => {
    if (value < 0.3) return 'Low Stress';
    if (value < 0.6) return 'Moderate Stress';
    return 'High Stress';
  };

  return (
    <div className="min-h-screen bg-gray-100 py-6 flex flex-col items-center">
      <div className="max-w-4xl w-full px-4">
        <h1 className="text-3xl font-bold text-center mb-8">Face Recognition Stress Detection</h1>
        
        {isLoading && (
          <div className="text-center text-blue-600">Loading face detection model...</div>
        )}

        {error && (
          <div className="text-center text-red-600 mb-4">{error}</div>
        )}

        <div className="relative mb-8">
          <video
            ref={videoRef}
            autoPlay
            playsInline
            muted
            className="w-full rounded-lg shadow-lg"
            style={{ display: error ? 'none' : 'block' }}
            width="640"
            height="480"
          />
          <canvas
            ref={canvasRef}
            className="absolute top-0 left-0 w-full h-full"
            width="640"
            height="480"
          />
        </div>

        {stressLevel !== null && !error && (
          <div className="bg-white p-6 rounded-lg shadow-lg">
            <h2 className="text-xl font-semibold mb-4">Stress Analysis</h2>
            <div className="flex items-center justify-between">
              <div className="text-lg">
                Stress Level: <span className="font-bold">{getStressLabel(stressLevel)}</span>
              </div>
              <div className="w-64 h-4 bg-gray-200 rounded-full overflow-hidden">
                <div
                  className="h-full transition-all duration-300"
                  style={{
                    width: `${stressLevel * 100}%`,
                    backgroundColor: stressLevel < 0.3 ? '#22c55e' : stressLevel < 0.6 ? '#eab308' : '#ef4444'
                  }}
                />
              </div>
              <div className="text-lg font-bold">
                {(stressLevel * 100).toFixed(1)}%
              </div>
            </div>
          </div>
        )}
      </div>
    </div>
  );
}

export default App;
